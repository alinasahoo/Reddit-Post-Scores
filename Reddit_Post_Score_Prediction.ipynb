{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reddit Post Score Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-RDvzC7NaM3",
        "outputId": "a74aa5cb-c6a5-48b4-aa92-1141c488281f"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('popular')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJCoaPxEntbm",
        "outputId": "1097ae73-2dd0-483e-ea4e-1fbabd961bfe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxChx38YJjOP"
      },
      "source": [
        "from numpy import array\r\n",
        "from numpy import asarray\r\n",
        "from numpy import zeros\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import numpy as np\r\n",
        "from collections import deque\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omJmSqupJmPF"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "import pickle"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2w5hnIGJrJS"
      },
      "source": [
        "data = pd.read_csv('ScrappedPostsData.csv')"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsVRnkxNKBb0"
      },
      "source": [
        "data.dropna(inplace=True)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OA0ICfyoMA3"
      },
      "source": [
        "data.drop(['Unnamed: 0','Upvote_ratio'], axis=1, inplace=True)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "eZHHFGiuPchC",
        "outputId": "de81958f-3e86-4f9b-f1e6-15ac72d77fbb"
      },
      "source": [
        "plt.figure(figsize=(20,15))\r\n",
        "plt.subplot(221)\r\n",
        "title_word_lengths = [len(str(data.Title.iloc[i]).split(' ')) for i in range(len(data))]\r\n",
        "max_title_word_length = max(title_word_lengths)\r\n",
        "min_title_word_length = min(title_word_lengths)\r\n",
        "average_title_word_length = sum(title_word_lengths)/len(title_word_lengths)\r\n",
        "plt.hist(title_word_lengths, bins = 30)\r\n",
        "print('Title word count lengths: \\n Min: {} \\n Max: {} \\n Average: {}'.format(min_title_word_length, max_title_word_length, average_title_word_length))\r\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title word count lengths: \n",
            " Min: 1 \n",
            " Max: 210 \n",
            " Average: 10.85932518597237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duFv27Q3IlnF"
      },
      "source": [
        "# data preprocessing\r\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\r\n",
        "import re\r\n",
        "\r\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\r\n",
        "lemmatizer = WordNetLemmatizer()\r\n",
        "stemmer = PorterStemmer()\r\n",
        "\r\n",
        "def text_preprocess(text):\r\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) \r\n",
        "    l_text = [word for word in text.lower().split() if word not in ENGLISH_STOP_WORDS]\r\n",
        "    stem_words = [stemmer.stem(w) for w in l_text]\r\n",
        "    lemma_words = [lemmatizer.lemmatize(w) for w in l_text]\r\n",
        "\r\n",
        "    return \" \".join(lemma_words)\r\n",
        "\r\n",
        "data['Title'] = data['Title'].map(lambda com : text_preprocess(com))"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "UBJOaU6NWMlr",
        "outputId": "669ba942-97ca-4833-e3c1-1dab4e0dabb4"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Score</th>\n",
              "      <th>Gilded</th>\n",
              "      <th>Over_18</th>\n",
              "      <th>Number_of_Comments</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>compound</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>people continue wearing mask pandemic end</td>\n",
              "      <td>40466</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>12754</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dear covid fuck covid icu nurse</td>\n",
              "      <td>15456</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>635</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.234</td>\n",
              "      <td>-0.2263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thailand elephant rescued abuse brought sanctu...</td>\n",
              "      <td>36866</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>645</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.607</td>\n",
              "      <td>0.305</td>\n",
              "      <td>0.8860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>philippine poised lift age consent sex decade ...</td>\n",
              "      <td>54377</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>2278</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.766</td>\n",
              "      <td>0.176</td>\n",
              "      <td>0.3818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>happening trump supporter trying destroy orego...</td>\n",
              "      <td>45937</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>4021</td>\n",
              "      <td>0.154</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.4215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  Score  ...    pos  compound\n",
              "0          people continue wearing mask pandemic end  40466  ...  0.000    0.0000\n",
              "1                    dear covid fuck covid icu nurse  15456  ...  0.234   -0.2263\n",
              "2  thailand elephant rescued abuse brought sanctu...  36866  ...  0.305    0.8860\n",
              "3  philippine poised lift age consent sex decade ...  54377  ...  0.176    0.3818\n",
              "4  happening trump supporter trying destroy orego...  45937  ...  0.276    0.4215\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEKIbA-ccGpj"
      },
      "source": [
        "i = 0\r\n",
        "\r\n",
        "predicted_value = []\r\n",
        "\r\n",
        "while i<len(data):\r\n",
        "  if (data.loc[i]['compound'] >= 0.5):\r\n",
        "    predicted_value.append('positive')\r\n",
        "    i = i+1\r\n",
        "\r\n",
        "  elif (data.loc[i]['compound'] >= 0) & (data.loc[i]['compound'] <= 0.5):\r\n",
        "    predicted_value.append('neutral')\r\n",
        "    i = i+1\r\n",
        "\r\n",
        "  elif (data.loc[i]['compound'] <= 0):\r\n",
        "    predicted_value.append('negative')\r\n",
        "    i = i+1"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BApFtMYfOUb"
      },
      "source": [
        "data['Predicted_value'] = predicted_value"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgUugb_ufUSn"
      },
      "source": [
        "data.drop(['neg', 'neu', 'pos', 'compound'], axis=1, inplace=True)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYdi5jvmPCxC"
      },
      "source": [
        "X = data.drop(['Score'], axis=1)\r\n",
        "y = data['Score']"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFA6QU_OfvAA",
        "outputId": "292a5e6a-0307-4485-a16f-a268d53459e3"
      },
      "source": [
        "lengths = max([len(x) for x in X.Title])\r\n",
        "lengths"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "278"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjN1MgOvKJ-O"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TonbD7jNKLgA"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\r\n",
        "tokenizer.fit_on_texts(X_train[\"Title\"])"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_EVgqi4gv0Y"
      },
      "source": [
        "train_title = tokenizer.texts_to_sequences(X_train[\"Title\"])\r\n",
        "test_title = tokenizer.texts_to_sequences(X_test[\"Title\"])\r\n",
        "\r\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Gf7sikIDOm"
      },
      "source": [
        "indixes = tokenizer.word_index\r\n",
        "tokens = {k:[indixes[k]] for k in indixes}\r\n",
        "df_tokens = pd.DataFrame(tokens)\r\n",
        "df_tokens.to_csv('tokens.csv', header=True, index=False)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O39OzsugKO0_"
      },
      "source": [
        "maxlen = 300\r\n",
        "\r\n",
        "train_title = pad_sequences(train_title, padding='post', maxlen=maxlen)\r\n",
        "test_title = pad_sequences(test_title, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpVFhOlfKQzS"
      },
      "source": [
        "embeddings_dictionary = dict()\r\n",
        "\r\n",
        "glove_file = open('/content/drive/My Drive/glove.6B.100d.txt', encoding=\"utf8\")\r\n",
        "\r\n",
        "for line in glove_file:\r\n",
        "    records = line.split()\r\n",
        "    word = records[0]\r\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\r\n",
        "    embeddings_dictionary[word] = vector_dimensions\r\n",
        "glove_file.close()"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVZOqt_tKVUF"
      },
      "source": [
        "embedding_matrix = zeros((vocab_size, 100))\r\n",
        "for word, index in tokenizer.word_index.items():\r\n",
        "    embedding_vector = embeddings_dictionary.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ObLLfBLKGkq"
      },
      "source": [
        "df = pd.DataFrame(data=embedding_matrix.astype(float))\r\n",
        "df.to_csv('embedding_matrix.csv', sep=' ', header=True, float_format='%.2f', index=False)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLOjS3kqLLzi"
      },
      "source": [
        "train_new = {}\r\n",
        "for i, sentence in enumerate(train_title):\r\n",
        "    vectors = []\r\n",
        "    for n in sentence:\r\n",
        "        vectors.append(embedding_matrix[n])\r\n",
        "    train_new[i] = vectors"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6j6KzGrLN80"
      },
      "source": [
        "test_new = {}\r\n",
        "for i, sentence in enumerate(test_title):\r\n",
        "    vectors = []\r\n",
        "    for n in sentence:\r\n",
        "        vectors.append(embedding_matrix[n])\r\n",
        "    test_new[i] = vectors"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2P2SK27LQRI"
      },
      "source": [
        "X_train_df = []\r\n",
        "for key in train_new:\r\n",
        "    arr = np.array(train_new[key])\r\n",
        "    X_train_df.append(np.mean(arr, axis=0))"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5Qc2kiuLSUA"
      },
      "source": [
        "X_test_df = []\r\n",
        "for key in test_new:\r\n",
        "    arr = np.array(test_new[key])\r\n",
        "    X_test_df.append(np.mean(arr, axis=0))"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATHo8IXPLUk1"
      },
      "source": [
        "X_train_df = pd.DataFrame(np.array(X_train_df))\r\n",
        "X_test_df = pd.DataFrame(np.array(X_test_df))"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvyHRjxUYNVA"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "\r\n",
        "categories = ['Over_18', 'Predicted_value']\r\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\r\n",
        "enc.fit(X_train[categories])\r\n",
        "pickle.dump(enc, open('one_hot.pkl','wb'))"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDd0KPZAdfLg"
      },
      "source": [
        "col_names = [j for sub in enc.categories_ for j in sub] "
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42cCcj2xe8mO",
        "outputId": "28ff9f37-ebd5-422e-aaa1-e934fb397f23"
      },
      "source": [
        "col_names"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False, True, 'negative', 'neutral', 'positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWYga4-bY_iG"
      },
      "source": [
        "train_encoded = enc.transform(X_train[categories])\r\n",
        "test_encoded = enc.transform(X_test[categories])"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBajHnZ-LXE-",
        "outputId": "675d75ba-4363-4499-ce96-5326637048d2"
      },
      "source": [
        "X_train.drop([\"Title\", 'Over_18', 'Predicted_value'], axis=1, inplace=True)\r\n",
        "X_test.drop([\"Title\", 'Over_18', 'Predicted_value'], axis=1, inplace=True)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QOGMu8rLaIa"
      },
      "source": [
        "X_train.reset_index(inplace=True, drop=True)\r\n",
        "X_test.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLv5i964c8RL"
      },
      "source": [
        "train = pd.DataFrame(train_encoded.todense(), columns=col_names)\r\n",
        "test = pd.DataFrame(test_encoded.todense(), columns=col_names)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "_uxS36L9fD9Y",
        "outputId": "8808907b-fd12-4085-bd71-6b501f3fed43"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>False</th>\n",
              "      <th>True</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   False  True  negative  neutral  positive\n",
              "0    1.0   0.0       0.0      1.0       0.0\n",
              "1    1.0   0.0       0.0      1.0       0.0\n",
              "2    1.0   0.0       0.0      1.0       0.0\n",
              "3    1.0   0.0       0.0      1.0       0.0\n",
              "4    1.0   0.0       0.0      1.0       0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSw1wZgBLcaI"
      },
      "source": [
        "X_train = pd.concat([X_train, X_train_df, train], axis=1)\r\n",
        "X_test = pd.concat([X_test, X_test_df, test], axis=1)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "y45aZhPLOiVs",
        "outputId": "4724e4fe-a108-4b8e-a4d1-7fa77f7ac230"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gilded</th>\n",
              "      <th>Number_of_Comments</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>...</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>False</th>\n",
              "      <th>True</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>-0.001442</td>\n",
              "      <td>0.002572</td>\n",
              "      <td>0.001396</td>\n",
              "      <td>-0.000855</td>\n",
              "      <td>0.001007</td>\n",
              "      <td>-0.000152</td>\n",
              "      <td>-0.000654</td>\n",
              "      <td>-0.000342</td>\n",
              "      <td>0.000799</td>\n",
              "      <td>-0.002514</td>\n",
              "      <td>-0.001796</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.004344</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.002888</td>\n",
              "      <td>-0.000628</td>\n",
              "      <td>-0.001018</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.001533</td>\n",
              "      <td>0.002309</td>\n",
              "      <td>0.003437</td>\n",
              "      <td>0.001069</td>\n",
              "      <td>-0.000544</td>\n",
              "      <td>-0.000029</td>\n",
              "      <td>0.001838</td>\n",
              "      <td>-0.001242</td>\n",
              "      <td>-0.001644</td>\n",
              "      <td>-0.001304</td>\n",
              "      <td>0.000287</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.003186</td>\n",
              "      <td>-0.001177</td>\n",
              "      <td>-0.000711</td>\n",
              "      <td>0.001419</td>\n",
              "      <td>0.003261</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>-0.000243</td>\n",
              "      <td>-0.001107</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003832</td>\n",
              "      <td>0.004244</td>\n",
              "      <td>-0.001411</td>\n",
              "      <td>0.001332</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>0.000923</td>\n",
              "      <td>-0.003411</td>\n",
              "      <td>-0.001714</td>\n",
              "      <td>-0.001157</td>\n",
              "      <td>0.000289</td>\n",
              "      <td>-0.002904</td>\n",
              "      <td>0.001654</td>\n",
              "      <td>0.001972</td>\n",
              "      <td>-0.004411</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.003280</td>\n",
              "      <td>-0.001016</td>\n",
              "      <td>-0.001442</td>\n",
              "      <td>-0.002754</td>\n",
              "      <td>-0.009053</td>\n",
              "      <td>-0.005863</td>\n",
              "      <td>-0.000298</td>\n",
              "      <td>-0.002147</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>-0.003503</td>\n",
              "      <td>0.001274</td>\n",
              "      <td>-0.002454</td>\n",
              "      <td>-0.000896</td>\n",
              "      <td>-0.000431</td>\n",
              "      <td>-0.003577</td>\n",
              "      <td>-0.000712</td>\n",
              "      <td>-0.002249</td>\n",
              "      <td>-0.002615</td>\n",
              "      <td>0.003140</td>\n",
              "      <td>0.001254</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0.001152</td>\n",
              "      <td>-0.000055</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>-0.002464</td>\n",
              "      <td>-0.001223</td>\n",
              "      <td>0.001911</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.001630</td>\n",
              "      <td>0.001593</td>\n",
              "      <td>-0.001790</td>\n",
              "      <td>-0.000927</td>\n",
              "      <td>-0.000070</td>\n",
              "      <td>0.002760</td>\n",
              "      <td>0.005914</td>\n",
              "      <td>0.002542</td>\n",
              "      <td>0.002074</td>\n",
              "      <td>-0.001778</td>\n",
              "      <td>0.000789</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>0.001323</td>\n",
              "      <td>-0.000030</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>-0.005082</td>\n",
              "      <td>-0.000129</td>\n",
              "      <td>0.009926</td>\n",
              "      <td>0.004685</td>\n",
              "      <td>-0.003142</td>\n",
              "      <td>-0.000973</td>\n",
              "      <td>0.007245</td>\n",
              "      <td>-0.002394</td>\n",
              "      <td>0.001977</td>\n",
              "      <td>0.004322</td>\n",
              "      <td>0.005463</td>\n",
              "      <td>0.002817</td>\n",
              "      <td>-0.000317</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>0.000675</td>\n",
              "      <td>-0.000570</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000374</td>\n",
              "      <td>0.002152</td>\n",
              "      <td>0.000168</td>\n",
              "      <td>-0.000879</td>\n",
              "      <td>-0.002507</td>\n",
              "      <td>-0.002335</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.001730</td>\n",
              "      <td>-0.000831</td>\n",
              "      <td>-0.000963</td>\n",
              "      <td>-0.000786</td>\n",
              "      <td>-0.003303</td>\n",
              "      <td>0.002347</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>-0.000638</td>\n",
              "      <td>0.000891</td>\n",
              "      <td>0.001120</td>\n",
              "      <td>0.001272</td>\n",
              "      <td>-0.005514</td>\n",
              "      <td>-0.001737</td>\n",
              "      <td>0.001396</td>\n",
              "      <td>0.002255</td>\n",
              "      <td>-0.000374</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>-0.000205</td>\n",
              "      <td>-0.000076</td>\n",
              "      <td>-0.000068</td>\n",
              "      <td>0.002739</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>0.001418</td>\n",
              "      <td>-0.003537</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>0.001878</td>\n",
              "      <td>0.000346</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0.001058</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>-0.000213</td>\n",
              "      <td>-0.002265</td>\n",
              "      <td>-0.002557</td>\n",
              "      <td>0.003873</td>\n",
              "      <td>-0.000871</td>\n",
              "      <td>0.001327</td>\n",
              "      <td>-0.004929</td>\n",
              "      <td>0.003158</td>\n",
              "      <td>0.002672</td>\n",
              "      <td>0.000358</td>\n",
              "      <td>-0.002374</td>\n",
              "      <td>0.004117</td>\n",
              "      <td>-0.001034</td>\n",
              "      <td>0.000669</td>\n",
              "      <td>0.001088</td>\n",
              "      <td>-0.003424</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.002256</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.002201</td>\n",
              "      <td>-0.002456</td>\n",
              "      <td>0.000588</td>\n",
              "      <td>0.002622</td>\n",
              "      <td>0.002554</td>\n",
              "      <td>-0.002652</td>\n",
              "      <td>-0.000251</td>\n",
              "      <td>-0.002618</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>0.002589</td>\n",
              "      <td>0.004451</td>\n",
              "      <td>-0.002851</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>0.003574</td>\n",
              "      <td>-0.000632</td>\n",
              "      <td>0.000665</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>0.003853</td>\n",
              "      <td>0.000752</td>\n",
              "      <td>0.000699</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>-0.000039</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.002223</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>0.003008</td>\n",
              "      <td>-0.000383</td>\n",
              "      <td>-0.001463</td>\n",
              "      <td>-0.000419</td>\n",
              "      <td>-0.000994</td>\n",
              "      <td>-0.001060</td>\n",
              "      <td>0.005584</td>\n",
              "      <td>-0.004343</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>-0.005201</td>\n",
              "      <td>-0.002135</td>\n",
              "      <td>0.002429</td>\n",
              "      <td>-0.001983</td>\n",
              "      <td>-0.003800</td>\n",
              "      <td>0.001324</td>\n",
              "      <td>0.000682</td>\n",
              "      <td>-0.000196</td>\n",
              "      <td>-0.001794</td>\n",
              "      <td>0.000896</td>\n",
              "      <td>-0.003757</td>\n",
              "      <td>-0.000507</td>\n",
              "      <td>-0.001019</td>\n",
              "      <td>-0.000696</td>\n",
              "      <td>-0.001129</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0.002586</td>\n",
              "      <td>-0.002090</td>\n",
              "      <td>-0.000494</td>\n",
              "      <td>-0.000723</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>-0.000667</td>\n",
              "      <td>0.000564</td>\n",
              "      <td>-0.002557</td>\n",
              "      <td>0.004949</td>\n",
              "      <td>-0.006141</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.005486</td>\n",
              "      <td>-0.002309</td>\n",
              "      <td>-0.003773</td>\n",
              "      <td>0.002510</td>\n",
              "      <td>-0.006349</td>\n",
              "      <td>0.001289</td>\n",
              "      <td>-0.003406</td>\n",
              "      <td>-0.004589</td>\n",
              "      <td>-0.001085</td>\n",
              "      <td>0.001606</td>\n",
              "      <td>0.003017</td>\n",
              "      <td>-0.003863</td>\n",
              "      <td>0.005617</td>\n",
              "      <td>-0.000793</td>\n",
              "      <td>-0.001102</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>-0.002225</td>\n",
              "      <td>0.003030</td>\n",
              "      <td>-0.001523</td>\n",
              "      <td>-0.002886</td>\n",
              "      <td>0.005291</td>\n",
              "      <td>-0.002822</td>\n",
              "      <td>0.002866</td>\n",
              "      <td>0.001827</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.002735</td>\n",
              "      <td>0.001282</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002163</td>\n",
              "      <td>0.004352</td>\n",
              "      <td>-0.000555</td>\n",
              "      <td>0.001888</td>\n",
              "      <td>-0.003806</td>\n",
              "      <td>0.002032</td>\n",
              "      <td>-0.004048</td>\n",
              "      <td>-0.004106</td>\n",
              "      <td>-0.006275</td>\n",
              "      <td>-0.002760</td>\n",
              "      <td>0.001775</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>-0.001698</td>\n",
              "      <td>-0.004419</td>\n",
              "      <td>-0.003410</td>\n",
              "      <td>0.006606</td>\n",
              "      <td>-0.003119</td>\n",
              "      <td>-0.000067</td>\n",
              "      <td>-0.001392</td>\n",
              "      <td>-0.009955</td>\n",
              "      <td>0.003875</td>\n",
              "      <td>-0.002600</td>\n",
              "      <td>-0.001378</td>\n",
              "      <td>-0.001347</td>\n",
              "      <td>-0.000579</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.005295</td>\n",
              "      <td>0.003561</td>\n",
              "      <td>0.009520</td>\n",
              "      <td>-0.000654</td>\n",
              "      <td>-0.000201</td>\n",
              "      <td>0.000349</td>\n",
              "      <td>-0.004536</td>\n",
              "      <td>-0.000481</td>\n",
              "      <td>0.002201</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>74</td>\n",
              "      <td>0.002095</td>\n",
              "      <td>-0.001389</td>\n",
              "      <td>0.002128</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>-0.000136</td>\n",
              "      <td>0.003090</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.000207</td>\n",
              "      <td>-0.003432</td>\n",
              "      <td>-0.002451</td>\n",
              "      <td>0.001173</td>\n",
              "      <td>-0.000225</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.004050</td>\n",
              "      <td>0.003206</td>\n",
              "      <td>-0.000789</td>\n",
              "      <td>-0.004403</td>\n",
              "      <td>-0.001892</td>\n",
              "      <td>-0.003310</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.005087</td>\n",
              "      <td>0.000371</td>\n",
              "      <td>-0.002490</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.002875</td>\n",
              "      <td>0.008118</td>\n",
              "      <td>0.000994</td>\n",
              "      <td>-0.000345</td>\n",
              "      <td>0.001632</td>\n",
              "      <td>-0.002089</td>\n",
              "      <td>0.003973</td>\n",
              "      <td>0.006256</td>\n",
              "      <td>0.003019</td>\n",
              "      <td>-0.000028</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>-0.000426</td>\n",
              "      <td>0.001638</td>\n",
              "      <td>-0.001947</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.002910</td>\n",
              "      <td>0.002968</td>\n",
              "      <td>-0.001254</td>\n",
              "      <td>-0.003910</td>\n",
              "      <td>-0.002701</td>\n",
              "      <td>-0.000285</td>\n",
              "      <td>0.001452</td>\n",
              "      <td>-0.004989</td>\n",
              "      <td>0.004137</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>-0.002116</td>\n",
              "      <td>-0.003051</td>\n",
              "      <td>-0.003008</td>\n",
              "      <td>0.001575</td>\n",
              "      <td>0.003356</td>\n",
              "      <td>-0.001350</td>\n",
              "      <td>-0.003678</td>\n",
              "      <td>-0.002062</td>\n",
              "      <td>-0.010014</td>\n",
              "      <td>-0.001772</td>\n",
              "      <td>-0.002111</td>\n",
              "      <td>-0.002755</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.003798</td>\n",
              "      <td>-0.000424</td>\n",
              "      <td>0.001249</td>\n",
              "      <td>-0.000580</td>\n",
              "      <td>0.003762</td>\n",
              "      <td>0.005452</td>\n",
              "      <td>0.004116</td>\n",
              "      <td>-0.000643</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.003167</td>\n",
              "      <td>-0.000351</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  107 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Gilded  Number_of_Comments         0  ...  negative  neutral  positive\n",
              "0       0                  39 -0.001442  ...       0.0      1.0       0.0\n",
              "1       0                  25  0.001152  ...       0.0      1.0       0.0\n",
              "2       0                  32  0.001058  ...       0.0      1.0       0.0\n",
              "3       0                  46  0.002586  ...       0.0      1.0       0.0\n",
              "4       1                  74  0.002095  ...       0.0      1.0       0.0\n",
              "\n",
              "[5 rows x 107 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00QRjSdaVAtB"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score, mean_absolute_error\r\n",
        "from sklearn.tree import DecisionTreeRegressor\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.neighbors import KNeighborsRegressor\r\n",
        "import xgboost as xgb\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-3yec1JL8Tw",
        "outputId": "8d2adb80-9a80-4750-b5db-2a47125ef2ca"
      },
      "source": [
        "lm=LinearRegression()   \r\n",
        "lm = lm.fit(X_train,y_train)\r\n",
        "\r\n",
        "#Traindata Predictions\r\n",
        "train_pred = lm.predict(X_train)\r\n",
        "\r\n",
        "#testdata predictions\r\n",
        "test_pred = lm.predict(X_test)\r\n",
        "\r\n",
        "\r\n",
        "RMSE_test = np.sqrt(mean_squared_error(y_test, test_pred))\r\n",
        "RMSE_train= np.sqrt(mean_squared_error(y_train,train_pred))\r\n",
        "print(\"RMSE TrainingData = \",str(RMSE_train))\r\n",
        "print(\"RMSE TestData = \",str(RMSE_test))\r\n",
        "print('-'*50)\r\n",
        "print('RSquared value on train:',lm.score(X_train, y_train))\r\n",
        "print('RSquared value on test:',lm.score(X_test, y_test))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE TrainingData =  7869.979472326438\n",
            "RMSE TestData =  8948.74957123513\n",
            "--------------------------------------------------\n",
            "RSquared value on train: 0.2771574493592297\n",
            "RSquared value on test: 0.07858682970448438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vDeq1jkL15F",
        "outputId": "f2849c1b-3e0d-4326-c6a5-bf7e0f422cea"
      },
      "source": [
        "DT=DecisionTreeRegressor()\r\n",
        "DT.fit(X_train,y_train)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6QG50eSMaYU"
      },
      "source": [
        "#predicting train\r\n",
        "train_preds=DT.predict(X_train)\r\n",
        "#predicting on test\r\n",
        "test_preds=DT.predict(X_test)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEfkUJs8MdhB",
        "outputId": "ba42bb72-f758-4ead-ef24-99abf432a4e0"
      },
      "source": [
        "RMSE_train=(np.sqrt(metrics.mean_squared_error(y_train,train_preds)))\r\n",
        "RMSE_test=(np.sqrt(metrics.mean_squared_error(y_test,test_preds)))\r\n",
        "print(\"RMSE TrainingData = \",str(RMSE_train))\r\n",
        "print(\"RMSE TestData = \",str(RMSE_test))\r\n",
        "print('-'*50)\r\n",
        "print('RSquared value on train:',DT.score(X_train, y_train))\r\n",
        "print('RSquared value on test:',DT.score(X_test, y_test))"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE TrainingData =  497.8744612234056\n",
            "RMSE TestData =  9950.356640873139\n",
            "--------------------------------------------------\n",
            "RSquared value on train: 0.9971070814288798\n",
            "RSquared value on test: -0.13921842507236204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75jGUB_XMiZg",
        "outputId": "94b37d0f-71cc-455f-b18a-c3d160831859"
      },
      "source": [
        "RF=RandomForestRegressor(n_jobs=-1)\r\n",
        "RF.fit(X_train,y_train)\r\n",
        "\r\n",
        "#predicting train\r\n",
        "train_preds1=RF.predict(X_train)\r\n",
        "#predicting on test\r\n",
        "test_preds1=RF.predict(X_test)\r\n",
        "\r\n",
        "RMSE_train=(np.sqrt(metrics.mean_squared_error(y_train,train_preds1)))\r\n",
        "RMSE_test=(np.sqrt(metrics.mean_squared_error(y_test,test_preds1)))\r\n",
        "print(\"RMSE TrainingData = \",str(RMSE_train))\r\n",
        "print(\"RMSE TestData = \",str(RMSE_test))\r\n",
        "print('-'*50)\r\n",
        "print('RSquared value on train:',RF.score(X_train, y_train))\r\n",
        "print('RSquared value on test:',RF.score(X_test, y_test))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE TrainingData =  2584.2517693774957\n",
            "RMSE TestData =  6865.266062991941\n",
            "--------------------------------------------------\n",
            "RSquared value on train: 0.9220589674147153\n",
            "RSquared value on test: 0.45769394652236606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi0Z4TR_OQCF"
      },
      "source": [
        "RF=RandomForestRegressor(n_jobs=-1)\r\n",
        "RF.fit(X_train,y_train)\r\n",
        "\r\n",
        "pickle.dump(RF, open('rf.pkl','wb'))"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dljkqiBnMtlO",
        "outputId": "14831a27-4d61-494f-d96f-607680d29f8f"
      },
      "source": [
        "knn=KNeighborsRegressor()\r\n",
        "knn.fit(X_train,y_train)\r\n",
        "\r\n",
        "#predicting train\r\n",
        "train_preds2=knn.predict(X_train)\r\n",
        "#predicting on test\r\n",
        "test_preds2=knn.predict(X_test)\r\n",
        "\r\n",
        "RMSE_train=(np.sqrt(metrics.mean_squared_error(y_train,train_preds2)))\r\n",
        "RMSE_test=(np.sqrt(metrics.mean_squared_error(y_test,test_preds2)))\r\n",
        "print(\"RMSE TrainingData = \",str(RMSE_train))\r\n",
        "print(\"RMSE TestData = \",str(RMSE_test))\r\n",
        "print('-'*50)\r\n",
        "print('RSquared value on train:',knn.score(X_train, y_train))\r\n",
        "print('RSquared value on test:',knn.score(X_test, y_test))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE TrainingData =  6042.175764031128\n",
            "RMSE TestData =  7451.644931659574\n",
            "--------------------------------------------------\n",
            "RSquared value on train: 0.5739277793990758\n",
            "RSquared value on test: 0.36109834692091725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3MrZDxSNuXn"
      },
      "source": [
        "from sklearn.linear_model import LassoCV\r\n",
        "from sklearn.linear_model import RidgeCV\r\n",
        "from sklearn.linear_model import ElasticNetCV\r\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65cOItTjjz8u",
        "outputId": "01916ed4-6022-44e5-f6ea-17bc30ac0a8c"
      },
      "source": [
        "lasso = LassoCV(cv=10).fit(X_train, y_train)\r\n",
        "\r\n",
        "\r\n",
        "#predicting train\r\n",
        "train_preds3=lasso.predict(X_train)\r\n",
        "#predicting on test\r\n",
        "test_preds3=lasso.predict(X_test)\r\n",
        "\r\n",
        "RMSE_train=(np.sqrt(metrics.mean_squared_error(y_train,train_preds3)))\r\n",
        "RMSE_test=(np.sqrt(metrics.mean_squared_error(y_test,test_preds3)))\r\n",
        "print(\"RMSE TrainingData = \",str(RMSE_train))\r\n",
        "print(\"RMSE TestData = \",str(RMSE_test))\r\n",
        "print('-'*50)\r\n",
        "print('RSquared value on train:',lasso.score(X_train, y_train))\r\n",
        "print('RSquared value on test:',lasso.score(X_test, y_test))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE TrainingData =  8034.932006086684\n",
            "RMSE TestData =  9049.800344322846\n",
            "--------------------------------------------------\n",
            "RSquared value on train: 0.24653874864045822\n",
            "RSquared value on test: 0.05765983503903849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EKyaYHsj92x",
        "outputId": "b1ce9912-c0a2-49e8-d737-abb3f3e6f7aa"
      },
      "source": [
        "ridge = RidgeCV(cv=10).fit(X_train, y_train)\r\n",
        "#predicting train\r\n",
        "train_preds4=ridge.predict(X_train)\r\n",
        "#predicting on test\r\n",
        "test_preds4=ridge.predict(X_test)\r\n",
        "\r\n",
        "RMSE_train=(np.sqrt(metrics.mean_squared_error(y_train,train_preds4)))\r\n",
        "RMSE_test=(np.sqrt(metrics.mean_squared_error(y_test,test_preds4)))\r\n",
        "print(\"RMSE TrainingData = \",str(RMSE_train))\r\n",
        "print(\"RMSE TestData = \",str(RMSE_test))\r\n",
        "print('-'*50)\r\n",
        "print('RSquared value on train:',ridge.score(X_train, y_train))\r\n",
        "print('RSquared value on test:',ridge.score(X_test, y_test))\r\n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE TrainingData =  7889.842912421455\n",
            "RMSE TestData =  8939.214392384392\n",
            "--------------------------------------------------\n",
            "RSquared value on train: 0.27350400671135056\n",
            "RSquared value on test: 0.08054937397011164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIrf-Wp9k07f",
        "outputId": "61317429-e818-4bf1-cf2c-0befabd32a70"
      },
      "source": [
        "elastic_net = ElasticNetCV(cv = 10).fit(X_train, y_train)\r\n",
        "#predicting train\r\n",
        "train_preds5=elastic_net.predict(X_train)\r\n",
        "#predicting on test\r\n",
        "test_preds5=elastic_net.predict(X_test)\r\n",
        "\r\n",
        "RMSE_train=(np.sqrt(metrics.mean_squared_error(y_train,train_preds5)))\r\n",
        "RMSE_test=(np.sqrt(metrics.mean_squared_error(y_test,test_preds5)))\r\n",
        "print(\"RMSE TrainingData = \",str(RMSE_train))\r\n",
        "print(\"RMSE TestData = \",str(RMSE_test))\r\n",
        "print('-'*50)\r\n",
        "print('RSquared value on train:',elastic_net.score(X_train, y_train))\r\n",
        "print('RSquared value on test:',elastic_net.score(X_test, y_test))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE TrainingData =  8042.3260607591355\n",
            "RMSE TestData =  9002.04898892087\n",
            "--------------------------------------------------\n",
            "RSquared value on train: 0.2451513823085296\n",
            "RSquared value on test: 0.06757813205862173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq38GaC3mSzQ",
        "outputId": "6b39068d-3079-4955-b9d0-458c577fe28d"
      },
      "source": [
        "xgbr =xgb.XGBRegressor().fit(X_train, y_train)\r\n",
        "#predicting train\r\n",
        "train_preds6=xgbr.predict(X_train)\r\n",
        "#predicting on test\r\n",
        "test_preds6=xgbr.predict(X_test)\r\n",
        "\r\n",
        "RMSE_train=(np.sqrt(metrics.mean_squared_error(y_train,train_preds6)))\r\n",
        "RMSE_test=(np.sqrt(metrics.mean_squared_error(y_test,test_preds6)))\r\n",
        "print(\"RMSE TrainingData = \",str(RMSE_train))\r\n",
        "print(\"RMSE TestData = \",str(RMSE_test))\r\n",
        "print('-'*50)\r\n",
        "print('RSquared value on train:',xgbr.score(X_train, y_train))\r\n",
        "print('RSquared value on test:',xgbr.score(X_test, y_test))"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17:25:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "RMSE TrainingData =  4977.608783561732\n",
            "RMSE TestData =  6559.128029755439\n",
            "--------------------------------------------------\n",
            "RSquared value on train: 0.7108401233491087\n",
            "RSquared value on test: 0.5049809383493384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8985qHJriUh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}